# -*- coding: utf-8 -*-
"""from post_id to topic_id .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xsDbpu91fe7HMzs1KCTqhqHJRPsnHoeQ
"""


import requests
import json
import openai
import os
from flask import Flask, request

app = Flask(__name__)
app.json.ensure_ascii = False

# 設定
# OpenAI APIキーの設定
openai.api_key = "YOUR_API_KEY"

# トピックリスト
with open('topics.json', 'r') as file:
    topics = json.load(file)

def extract_text(json_data):
    """
    Extract text from the given JSON data structure

    Args:
        json_data (dict): Input JSON data containing posts

    Returns:
        str: Extracted text from the post
    """
    try:
        # データ配列の最初の要素からtextフィールドを取得
        text = json_data['data'][0]['text']
        return text
    except (KeyError, IndexError) as e:
        return f"Error extracting text: {str(e)}"


def get_birdxplorer_data(post_id):
    """
    Fetches data from BirdXplorer API for a given post ID.

    Args:
        post_id: The ID of the post to retrieve data for.

    Returns:
        A JSON object containing the data from the API, or None if there was an error.
    """
    url = f"https://birdxplorer.onrender.com/api/v1/data/posts?post_ids={post_id}"
    try:
        response = requests.get(url)
        response.raise_for_status()  # Raise an exception for bad status codes (4xx or 5xx)
        data = response.json()
        return extract_text(data)
    except requests.exceptions.RequestException as e:
        print(f"Error fetching data from BirdXplorer: {e}")
        return None


# トピックId検索
import json
def search_topic_ids(search_words, json_data):
    """
    Search for words in JSON data and return their corresponding topic IDs.

    Args:
        search_words (list): List of words to search for
        json_data (str): JSON string containing the topic data

    Returns:
        dict: Dictionary with search words as keys and topic IDs or "Not found" as values
    """

    # Create a dictionary to store results
    results = {}
    # Search through the data
    for word in search_words.split(','):
        found = False
        lower_word = word.lower()
        for topic in json_data['data']:
            # Check both English and Japanese labels
            if (lower_word == topic['label']['en'].lower() or
                lower_word == topic['label']['ja'].lower()):
                results[word] = topic['topicId']
                found = True
                break
        if not found:
            results[word] = "Not found"

    return results

def get_closest_topic(text, topics):
    # トピックラベルとトピックIDのマッピングを作成
    topic_labels = {topic['label']['en']: topic['topicId'] for topic in topics['data']}

    # プロンプトを作成
    prompt = f"""Given the following text:\n{text}\n
    Please find the most relevant topic from this list.
    Output must be words, separated by commas.
    You have to use words in the list as priority: {', '.join(topic_labels.keys())}.
    If the relevant topic is not in the list, please return any other relevant words, also separated by commas."""

    # OpenAI APIを使用して関連性を評価
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": prompt}
        ]
    )

    # APIの応答からトピックを取得
    most_relevant_topic = response['choices'][0]['message']['content'].strip()

    # トピックIDを取得
    topic_id = search_topic_ids(most_relevant_topic, topics)

    return most_relevant_topic, topic_id


# jsonに成形
def format_topics_result(topic_label, topics_json):
    """
    Format the topic search results into the required JSON structure

    Args:
        topic_label (str): Comma-separated topic labels from GPT
        topics_json (dict): Original topics JSON data

    Returns:
        dict: Formatted JSON with required structure
    """
    # Initialize result structure
    result = {"data": []}

    # Process each topic label
    for label in topic_label.split(','):
        label = label.strip()
        topic_entry = {}

        # Check if topic exists in original JSON
        found = False
        for topic in topics_json['data']:
            if label.lower() == topic['label']['en'].lower():
                # Use existing topic data
                topic_entry = {
                    "topicId": topic['topicId'],
                    "label": {
                        "ja": topic['label']['ja'],
                        "en": topic['label']['en']
                    },
                    "referenceCount": topic['referenceCount']
                }
                found = True
                break

        if not found:
            # For new topics, get Japanese translation
            ja_label = get_japanese_translation(label)
            topic_entry = {
                "topicId": None,
                "label": {
                    "ja": ja_label,
                    "en": label
                },
                "referenceCount": None
            }

        result['data'].append(topic_entry)

    return result

def get_japanese_translation(english_text):
    """
    Get Japanese translation for English text using OpenAI API

    Args:
        english_text (str): English text to translate

    Returns:
        str: Japanese translation
    """
    prompt = f"Translate the following English term to Japanese, considering the context of news topics: {english_text}"

    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "You are a helpful assistant that translates English to Japanese. Please provide only the translated text without any explanation or notes."},
            {"role": "user", "content": prompt}
        ]
    )

    return response['choices'][0]['message']['content'].strip()

# 既存のget_closest_topicの結果を使用して最終的なJSONを生成
def process_text(text, topics_json):
    """
    Process input text and return formatted topic data

    Args:
        text (str): Input text to analyze
        topics_json (dict): Original topics JSON data

    Returns:
        dict: Formatted topic data in required JSON structure
    """
    # 既存の関数を使用してトピックを取得
    topic_label, _ = get_closest_topic(text, topics_json)

    # 結果を指定のフォーマットに整形
    formatted_result = format_topics_result(topic_label, topics_json)

    return formatted_result

# 使用例
# if __name__ == "__main__":
#     sample_text = "O Filho do Donald Trump e a sua esposa resolveram fazer uma \"motociata\" versão \"barcociata\". O detalhe nessa história é que nos EUA eles não precisam fingir que não são nazifascistas, então assim ficou a \"barcociata\" deles:"

#     result = process_text(sample_text, topics)
#     print(json.dumps(result, ensure_ascii=False, indent=2))

@app.route('/', methods=['GET'])
def handler():
    # GET 引数から Xの Post IDを受け取る
    post_id = request.args.get("post_id")
    print("get post_id:", post_id)

    if post_id=="":
        print("post_id was null")
        exit;
    text = get_birdxplorer_data(post_id)
    result = process_text(text, topics)
    return result

if __name__ == '__main__':
    # Cloud Run の環境変数 PORT からポート番号を取得
    port = int(os.environ.get('PORT', 8080))
    app.run(host='0.0.0.0', port=port)


# 実装確認（topicIdリストに関係ないテキスト）

# if __name__ == "__main__":
#     sample_text = "この衛星画像は  ランドサット衛星によって2018年10月1日撮影されたものであり  https://apps.sentinel-hub.com/eo-browser/?zoom=12&amp;lat=35.55485&amp;lng=139.85544&amp;themeId=DEFAULT-THEME&amp;visualizationUrl=U2FsdGVkX1%2BKkOV70GLKHRKgIxF8zblYfbfl3w34HbR%2F52RZFk63Lwcs%2BKlt5Z7d3AjkiOftnUQDujNhiFIqaQ6%2B4zifZprQ%2B5SO3%2B8YtKDy37aQu6VaiyqVeukml9ur&amp;datasetId=AWS_LOTL1&amp;fromTime=2018-10-01T00%3A00%3A00.000Z&amp;toTime=2018-10-01T23%3A59%3A59.999Z&amp;layerId=1_TRUE_COLOR&amp;demSource3D=%22MAPZEN%22    2018年9月末、10月1日にかけての降水量  https://www.data.jma.go.jp/stats/etrn/view/daily_s1.php?prec_no=44&amp;block_no=47662&amp;year=2018&amp;month=09&amp;day=&amp;view=g_pre  https://www.data.jma.go.jp/stats/etrn/view/daily_s1.php?prec_no=44&amp;block_no=47662&amp;year=2018&amp;month=10&amp;day=&amp;view=g_pre  が増加したことにより、土砂（泥）が河川に流入し  色の変化が起こっただけです。  汚染部質による色の変化ではありません。"
#     result = process_text(sample_text, topics)
#     print(json.dumps(result, ensure_ascii=False, indent=2))
